<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Alejandro Nolla - z0mbiehunt3r]]></title>
  <link href="http://blog.alejandronolla.com/atom.xml" rel="self"/>
  <link href="http://blog.alejandronolla.com/"/>
  <updated>2013-05-05T19:51:05+02:00</updated>
  <id>http://blog.alejandronolla.com/</id>
  <author>
    <name><![CDATA[Alejandro Nolla]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[solr: Improving queries performance]]></title>
    <link href="http://blog.alejandronolla.com/2013/04/29/solr-improving-queries-performance/"/>
    <updated>2013-04-29T20:29:00+02:00</updated>
    <id>http://blog.alejandronolla.com/2013/04/29/solr-improving-queries-performance</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>These days i&#8217;m messing around with an application that index thousands of documents per day and perform hundreds of queries per hour, so query performance is crucial. The main aim is to provide detection of URLs and IP addresses (want to play a bit? take a look to <a href="http://blog.alejandronolla.com/2013/03/23/indexing-pdf-for-osint-and-pentesting/">a previous post</a>) but full-text searching capabilities is also desired althought less used, so i have given a try to improve performance and, specifically, query times, and here is my tests results.<!-- more --></p>

<p>Actually the core&#8217; schema.xml it&#8217;s something like this:</p>

<figure class='code'><figcaption><span>initial schema.xml file</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
</span><span class='line'><span class="nt">&lt;schema</span> <span class="na">name=</span><span class="s">&quot;example&quot;</span> <span class="na">version=</span><span class="s">&quot;1.5&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>  <span class="nt">&lt;fields&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;id&quot;</span> <span class="na">type=</span><span class="s">&quot;uuid&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">default=</span><span class="s">&quot;NEW&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text&quot;</span> <span class="na">type=</span><span class="s">&quot;text_general&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;url&quot;</span> <span class="na">type=</span><span class="s">&quot;string&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">required=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;hash&quot;</span> <span class="na">type=</span><span class="s">&quot;string&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">required=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/fields&gt;</span>
</span><span class='line'>  <span class="nt">&lt;uniqueKey&gt;</span>hash<span class="nt">&lt;/uniqueKey&gt;</span>
</span><span class='line'>  <span class="nt">&lt;types&gt;</span>
</span><span class='line'>    <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;uuid&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.UUIDField&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;string&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.StrField&quot;</span> <span class="na">sortMissingLast=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;text_general&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TextField&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;index&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.WhitespaceTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;query&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.WhitespaceTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/fieldType&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/types&gt;</span>
</span><span class='line'><span class="nt">&lt;/schema&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
As can be seen, it only indexes and store given text, url and hash (used for avoid dupes), converting case to lower and tokenizing by whitespaces. This means that a document with content &#8220;SPAM Visit blog.alejandronolla.com&#8221; will be tokenized to &#8220;[&#8216;spam&#8217;, &#8216;visit&#8217;, &#8216;blog.alejandronolla.com&#8217;]&#8221; so, if we want to search documents mentioning any subdomain of alejandronolla.com we would have to search something like &#8220;text:*alejandronolla.com&#8221; (it could vary based on decisions like looking for domains similar to alejandronolla.com.PHISINGSITE.com or just whatever.alejandronolla.com).</p>

<p>This kind of queries, using leading/trailing wildcars, are really expensive for solr because it can&#8217;t use just indexed tokens but perform some walking up to &#8220;n&#8221; characters more.</p>

<h2>Avoiding solr heap space problems</h2>

<p>When dealing with a lot of documents concurrently probably you&#8217;re going to face heap space problems sooner or later so i strongly recommend to increase RAM asigned to java virtual machine.</p>

<p>In this case i use Tomcat to serve solr, so i needed to modify JAVA_OPTS in catalina.sh (stored at <em>&#8220;/usr/share/tomcat7/bin/catalina.sh&#8221;</em>):</p>

<figure class='code'><figcaption><span>Setting up values for RAM usage</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="k">if</span> <span class="o">[</span> -z <span class="s2">&quot;$LOGGING_MANAGER&quot;</span> <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span><span class="nv">JAVA_OPTS</span><span class="o">=</span><span class="s2">&quot;$JAVA_OPTS -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms2048m -Xmx16384m&quot;</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">  </span><span class="nv">JAVA_OPTS</span><span class="o">=</span><span class="s2">&quot;$JAVA_OPTS $LOGGING_MANAGER -Xms2048m -Xmx16384m&quot;</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></td></tr></table></div></figure>


<p>Adding <em>&#8220;-Xms2048m -Xmx16384m&#8221;</em> we specify tomcat to preallocate at least 2048MB and maximum of 16384MB for heap space for avoiding heap space problems (in my tests i almost used about 2GB indexing about 300k documents in two differents cores, so there is plenty of RAM left yet):<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/jvm.png"></p>

<h2>Handling thousand of concurrent connections with Tomcat</h2>

<p>We have to set some configuration at <em>&#8220;/etc/tomcat6/server.xml&#8221;</em>:</p>

<figure class='code'><figcaption><span>Tomcat configuration</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;Connector</span> <span class="na">port=</span><span class="s">&quot;8080&quot;</span> <span class="na">protocol=</span><span class="s">&quot;HTTP/1.1&quot;</span>
</span><span class='line'>           <span class="na">connectionTimeout=</span><span class="s">&quot;20000&quot;</span>
</span><span class='line'>           <span class="na">URIEncoding=</span><span class="s">&quot;UTF-8&quot;</span>
</span><span class='line'>           <span class="na">redirectPort=</span><span class="s">&quot;8443&quot;</span>
</span><span class='line'>           <span class="na">maxThreads=</span><span class="s">&quot;10000&quot;</span><span class="nt">/&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
I have set up maxThreads to 10000 because i want to index documents through API REST with a python script using async HTTP requests to avoid loosing too much time indexing data (and i&#8217;m almost sure bottleneck here is python and not solr).</p>

<h2>First improvement: Separate the grain from the chaff</h2>

<p>As previously said, most of the queries looks for domains and IP addresses through full document&#8217;s content, causing really heavy queries (and performance problems), so the first action i took was to create a new fields just with &#8220;domains look&#8217;s like&#8221; string and IP addresses to tie down queries just to potentially valuable info.</p>

<p>To extract domains, emails and similar strings solr already have a really powerful tokenizer called <a href="http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#solr.UAX29URLEmailTokenizerFactory">solr.UAX29URLEmailTokenizerFactory</a>, so we only need to tell solr to index given document text using this tokenizer in another field.</p>

<p>To specify solr which and where field we want to copy we have to create two new fields and specify source and destination fields:</p>

<figure class='code'><figcaption><span>New copied fields at schema.xml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;fields&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">type=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;false&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">type=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;false&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/fields&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;copyField</span> <span class="na">source=</span><span class="s">&quot;text&quot;</span> <span class="na">dest=</span><span class="s">&quot;text_UAX29&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>  <span class="nt">&lt;copyField</span> <span class="na">source=</span><span class="s">&quot;text&quot;</span> <span class="na">dest=</span><span class="s">&quot;ip_addresses&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>
</span><span class='line'>  <span class="nt">&lt;types&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TextField&quot;</span> <span class="na">positionIncrementGap=</span><span class="s">&quot;100&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;index&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.UAX29URLEmailTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;query&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.UAX29URLEmailTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/fieldType&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;/types&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
We are going to use these fields only for searching, so we specify to index but not store (we already have full document content in &#8220;text&#8221; field) It&#8217;s important to have in mind the fact that solr copy fields <a href="http://wiki.apache.org/solr/SchemaXml#Copy_Fields">before</a> doing any kind of processing to document.</p>

<p>If you have noticed it, we specified an undeclared field type called &#8220;ip_addresses&#8221;, and we are going to use <a href="http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#solr.PatternTokenizerFactory">solr.PatternTokenizerFactory</a> to make a regex for extracting IP addresses and CIDR network ranges (like 192.168.1.0/16)</p>

<figure class='code'><figcaption><span>Extracting IP addresses with regex</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;types&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TextField&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.PatternTokenizerFactory&quot;</span> <span class="na">pattern=</span><span class="s">&quot;(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}/?\d{1,2})&quot;</span> <span class="na">group=</span><span class="s">&quot;1&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/fieldType&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;/types&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
It&#8217;s a really simple regex and should be improved before using it in a production environment for example, to extract only certain IP addresses (not RFC1918, not bogus, quad-octet validated, and so on) or even implement your own tokenizer extending <a href="http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters">existing ones</a>, but will fit ok for our tests.</p>

<p>Now we can change queries from &#8220;text:*alejandronolla.com&#8221; to &#8220;text_UAX29:*alejandronolla.com&#8221; to walk much smaller subset of data, improving queries in a huge way.</p>

<h2>Second improvement: Don&#8217;t waste resources in features not being used</h2>

<p>Solr is a really powerful full-text search engine and, as such, it is able to perform several kind of analysis for indexed data in an automated way. Obviously those analysis need resources to be made so we are wasting CPU cycles and RAM if we are not going to use them.</p>

<p>One of these features is related to solr capability for boosting some query results over others and is based on certain &#8220;weight&#8221;. For example, two documents mentioning &#8220;solr&#8221; keyword just one time - one with a length of just few words and the other having several thousands - will have different relevances for solr engine, being more important the smallest one. This is because of term frequency-inverse document frequeny (usually refered as <a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">tf-idf</a>) statistic approach, if same keyword appear same number of time it represents a bigger percentage of the entire document in the smallest one.</p>

<p>Because we are not going to use this feature we can disable it and save some resources modifying schema.xml file:</p>

<figure class='code'><figcaption><span>Avoiding some statistical analysis</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;fields&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text&quot;</span> <span class="na">type=</span><span class="s">&quot;text_general&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;url&quot;</span> <span class="na">type=</span><span class="s">&quot;string&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">required=</span><span class="s">&quot;true&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">type=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;false&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">type=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;false&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>  <span class="nt">&lt;/fields&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
By setting &#8220;omitNorms&#8221; to &#8220;true&#8221; we specify solr to not don&#8217;t care about length normalization or index-time boosting, you can check the <a href="http://wiki.apache.org/solr/SchemaXml">wiki</a> for more information.</p>

<p>Another feature we don&#8217;t need now is the solr ability to find similar documents to given one (feature called <a href="http://wiki.apache.org/solr/MoreLikeThis">MoreLikeThis</a>). To do this we can take several approaches as compare tf-idf values or, more accurate way, represent each document as a vector (<a href="http://en.wikipedia.org/wiki/Vector_space_model">vector space model</a>) and find near ones (solr mix both).</p>

<p>Because we are not going to use this feature we can set it off by specifying following field options:</p>

<figure class='code'><figcaption><span>Disabling vector space model at schema.xml</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;fields&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text&quot;</span> <span class="na">type=</span><span class="s">&quot;text_general&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span> <span class="na">termVectors=</span><span class="s">&quot;false&quot;</span> <span class="na">termsPositions=</span><span class="s">&quot;false&quot;</span> <span class="na">termOffsets=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;url&quot;</span> <span class="na">type=</span><span class="s">&quot;string&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">required=</span><span class="s">&quot;true&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span> <span class="na">termVectors=</span><span class="s">&quot;false&quot;</span> <span class="na">termsPositions=</span><span class="s">&quot;false&quot;</span> <span class="na">termOffsets=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">type=</span><span class="s">&quot;ip_addresses&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;false&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span> <span class="na">termVectors=</span><span class="s">&quot;false&quot;</span> <span class="na">termsPositions=</span><span class="s">&quot;false&quot;</span> <span class="na">termOffsets=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">type=</span><span class="s">&quot;text_UAX29&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;false&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="na">omitNorms=</span><span class="s">&quot;true&quot;</span> <span class="na">termVectors=</span><span class="s">&quot;false&quot;</span> <span class="na">termsPositions=</span><span class="s">&quot;false&quot;</span> <span class="na">termOffsets=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>  <span class="nt">&lt;/fields&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
I have disabled them with these options &#8221;<em>termVectors=&#8221;false&#8221; termsPositions=&#8221;false&#8221; termOffsets=&#8221;false&#8221;</em>&#8221; and gain some performance boost.</p>

<p>If you want to know which field options to use based on your application aim take a look to official <a href="http://wiki.apache.org/solr/FieldOptionsByUseCase">wiki</a>:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/fieldoptionsbyusecase.png"></p>

<h2>Third improvement: Avoid indexing stopwords</h2>

<p>When doing natural lenguage processing the term &#8220;stopwords&#8221; is used to refer those words that should be removed before processing text because of their uselessness. For example, when indexing a document with content like &#8220;Visit me at blog.alejandronolla.com&#8221; we don&#8217;t care about personal pronoun &#8220;me&#8221; and preposition &#8220;at&#8221; (<a href="http://en.wikipedia.org/wiki/Part-of-speech_tagging">take a look to part-of-speech tagging</a>) so less indexed words, less used resources.</p>

<p>To avoid processing those words we need to specify solr where stopwords are located:</p>

<figure class='code'><figcaption><span>Avoiding stopwords being processed</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;fields&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>    <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;text_general&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TextField&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;index&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.WhitespaceTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.StopFilterFactory&quot;</span> <span class="na">ignoreCase=</span><span class="s">&quot;true&quot;</span> <span class="na">words=</span><span class="s">&quot;stopwords.txt&quot;</span> <span class="na">enablePositionIncrements=</span><span class="s">&quot;true&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;query&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.WhitespaceTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.StopFilterFactory&quot;</span> <span class="na">ignoreCase=</span><span class="s">&quot;true&quot;</span> <span class="na">words=</span><span class="s">&quot;stopwords.txt&quot;</span> <span class="na">enablePositionIncrements=</span><span class="s">&quot;true&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/fieldType&gt;</span>
</span><span class='line'>    [...]
</span><span class='line'>  <span class="nt">&lt;/fields&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
We need to have a file called <em>&#8220;stopwords.txt&#8221;</em> at our <em>&#8220;conf&#8221;</em> directory for specified core containing these words and we can find some stopwords for several languages in the example configuration provided with solr package at <em>&#8220;/PATH/TO/SOLR/CORE/conf/lang&#8221;</em>:</p>

<figure class='code'><figcaption><span>Some English stopwords</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>root@ph0b0s:/opt/solr/solr/conf/lang# tail stopwords_en.txt
</span><span class='line'>their
</span><span class='line'><span class="k">then</span>
</span><span class='line'>there
</span><span class='line'>these
</span><span class='line'>they
</span><span class='line'>this
</span><span class='line'>to
</span><span class='line'>was
</span><span class='line'>will
</span><span class='line'>with
</span></code></pre></td></tr></table></div></figure>


<p>
Of course, we can also include as stop words common words that don&#8217;t give us any useful information like dog, bread, ROI, APT and so on&#8230;</p>

<h2>Fourth impromevent: Word stemming</h2>

<p>Despite of haven&#8217;t used stemming yet in solr environments it&#8217;s possible to convert a given word to his morphological root through an <a href="http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters#Stemming">stemming</a> process:</p>

<figure class='code'><figcaption><span>Stemming word with python example</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">nltk.stemmer.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="n">PorterStemmer</span><span class="p">()</span><span class="o">.</span><span class="n">stem_word</span><span class="p">(</span><span class="s">&#39;documents&#39;</span><span class="p">)</span>
</span><span class='line'><span class="s">&#39;document&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
Because we &#8220;reduce&#8221; words to his root probably few of them, per document, will share stem and this will result in a smaller index and more performance booster.</p>

<h2>Fifth improvement: Don&#8217;t ask the same two times</h2>

<p>Depending on application data and workflow it could be really useful to cache &#8220;n&#8221; most common queries/filters/documents and avoid doing over and over the same query in a few minutes apart, i&#8217;m sorry but haven&#8217;t played around too much with it, so to read more about this go to the <a href="http://wiki.apache.org/solr/SolrCaching">wiki</a>.</p>

<h2>Results</h2>

<p>After taking first two improvements actions did some performance test and comparisons, so here are some info for a &#8220;small&#8221; subset of about 300k documents:</p>

<table border="1">
    <tr>
        <td></td>
        <td align="right">Original schema</td>
        <td align="right">Modified schema</td>
    </tr>
    <tr>
        <td align="left">Indexing time: </td>
        <td align="right">95 minutes</td>
        <td align="right">101 minutes</td>
    </tr>
    <tr>
        <td align="left">Index size: </td>
        <td align="right">555.12 MB</td>
        <td align="right">789.8 MB</td>
    </tr>
    <tr>
        <td align="left">Field being queried: </td>
        <td align="right">text</td>
        <td align="right">text_UAX29</td>
    </tr>
    <tr>
        <td align="left">Worst query scenario: </td>
        <td align="right">84766 milliseconds</td>
        <td align="right">52417 milliseconds</td>
    </tr>
    <tr>
        <td align="left">Worst query improvement: </td>
        <td align="center">&#8211;</td>
        <td align="right">38,2% faster</td>
    </tr>
</table>


<p></p>

<p>As shown in the above table, the &#8220;worst&#8221; query i&#8217;m now performing (dozens of logical operators and wildcards) will take about 38% time less per query hit and, in an application which performs hundreds of query per hour, it&#8217;s a great improvement without disrupting normal functioning (looking for domains and IP addresses) and, in the other hand, it will take almost no more time to index and more than reasonable index size increment that worth it.</p>

<p>Hope you liked it and can apply someway to your needs, see you soon!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moloch: Capturing and indexing network traffic in realtime]]></title>
    <link href="http://blog.alejandronolla.com/2013/04/06/moloch-capturing-and-indexing-network-traffic-in-realtime/"/>
    <updated>2013-04-06T00:40:00+02:00</updated>
    <id>http://blog.alejandronolla.com/2013/04/06/moloch-capturing-and-indexing-network-traffic-in-realtime</id>
    <content type="html"><![CDATA[<h2>What is moloch?</h2>

<p>As his own <a href="https://github.com/aol/moloch">website</a> says: <strong><em>&#8220;Moloch is an open source, large scale IPv4 packet capturing (PCAP), indexing and database system. A simple web interface is provided for PCAP browsing, searching, and exporting. APIs are exposed that allow PCAP data and JSON-formatted session data to be downloaded directly.&#8221;</em></strong> it will be very useful as a network forensic tool to analyze captured traffic (moloch can also index previously captured pcap files as we will see) in case of a security incident or detecting some suspicious behaviour like, for example, some kind of alert in our IDS.</p>

<p>Thanks of indexing pcaps with <a href="http://www.elasticsearch.org/">elasticsearch</a>, moloch provide us with the ability to perform almost real-time searches among dozens or hundreds of captured GB network traffic being able to apply several filtering options on the way. It isn&#8217;t as complete as Wireshark filtering system for example but will save us tons of work when dealing with some filtering and visualization as well as Moloch will provide us with some features Wireshark lacks, like filtering by country or AS.</p>

<p>I&#8217;m sure to not be the only who would have loved to rely on moloch when analyzing dozens of GB with tshark and wireshark, particularly each time you apply a filter to show some kind of data&#8230;<!-- more --></p>

<h2>Installing moloch</h2>

<p>For deploying a moloch machine in a &#8220;all-in-one&#8221; setup i created a virtual machine with Ubuntu server 12.10 64bits and assigned about 100GB of HDD, 16GB of RAM and 4 CPU cores, moloch is a highly consuming platform, to have a more detailed info about this go to <a href="https://github.com/aol/moloch#id23">hardware requirements</a>.</p>

<p>First step will be updating the box, installing java and cloning github repository:</p>

<figure class='code'><figcaption><span>Updating system and cloning repo</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># apt-get update &amp;&amp; apt-get upgrade -y &amp;&amp; apt-get install git openjdk-7-jdk openjdk-7-jre -y</span>
</span><span class='line'>
</span><span class='line'><span class="c"># git clone https://github.com/aol/moloch.git</span>
</span></code></pre></td></tr></table></div></figure>


<p>Once cloned the repo we must install, at least, one of his components: capture, viewer or elasticsearch. Because we are going to mess up a bit with moloch to get an overview of functionalities and capabilities we will take the shortest path, installing moloch through provided bash script to setup everything in the same machine; if you prefer to install it manually or are going to build a distributed cluster check &#8221;<a href="https://github.com/aol/moloch#id15">Building and Installing</a>&#8221;:</p>

<figure class='code'><figcaption><span>Installing moloch automatically</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>~/moloch# ./easybutton-singlehost.sh
</span></code></pre></td></tr></table></div></figure>


<p>Now the wizard will make us a few questions to configure moloch (capturer, viewer and elasticsearch instance) for us and everything will be running in a few moments (moloch will be installed by default at <em>&#8220;/data/moloch/&#8221;</em>) and we can access to web interface at <em>&#8220;https://MOLOCH_IP_ADDRESS:8005&#8221;</em>:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/moloch_fresh_install.png"></p>

<p>As can be seen, moloch have already started to index all traffic seen on eth0, included every request to moloch web interface. If we don&#8217;t want this then we have to specify a capture filtering in <em><a href="http://en.wikipedia.org/wiki/Berkeley_Packet_Filter">Berkeley Packet Filter (bpf)</a></em> format at <em>&#8220;/data/moloch/etc/config.ini&#8221;</em>:</p>

<figure class='code'><figcaption><span>Don&#8217;t index ANY traffic related with moloch box</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">bpf</span><span class="o">=</span>not host 192.168.1.39
</span></code></pre></td></tr></table></div></figure>


<p>To change elasticsearch configuration and allow access from other IP address than moloch host itself (it could pose a security risk, using SSH tunneling would be a better aproach) go to <em>&#8220;/data/moloch/etc/elasticsearch.yml&#8221;</em> and edit network parameters (<em>network.host</em>), to view/change moloch configuration take a look to <em>&#8220;/data/moloch/etc/config.ini&#8221;</em>:</p>

<figure class='code'><figcaption><span>Changing binded IP address</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># Set the bind address specifically (IPv4 or IPv6):</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'>network.bind_host: 0.0.0.0
</span><span class='line'>
</span><span class='line'><span class="c"># Set the address other nodes will use to communicate with this node. If not</span>
</span><span class='line'><span class="c"># set, it is automatically derived. It must point to an actual IP address.</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'>network.publish_host: 0.0.0.0
</span><span class='line'>
</span><span class='line'><span class="c"># Set both &#39;bind_host&#39; and &#39;publish_host&#39;:</span>
</span><span class='line'><span class="c">#</span>
</span><span class='line'>network.host: 0.0.0.0
</span></code></pre></td></tr></table></div></figure>


<p>
We need to shutdown elasticsearch node and start it again, so here we go:</p>

<figure class='code'><figcaption><span>Restarting elasticsearch</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># curl -XPOST &#39;http://localhost:9200/_shutdown&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># nohup /data/moloch/bin/run_es.sh &amp;</span>
</span></code></pre></td></tr></table></div></figure>


<p>
We can also start viewer and capturer from same dir <em>&#8220;/data/moloch/bin/run_viewer.sh&#8221;</em> and <em>&#8220;/data/moloch/bin/run_capture.sh&#8221;</em> respectively.<br/>
Now we have access to <a href="http://mobz.github.com/elasticsearch-head/">elasticsearch-head</a> plugin to see elasticsearch cluster health and manage it at <em>&#8220;https://MOLOCH_IP_ADDRESS:9200/_plugin/head/&#8221;</em>:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/elasticsearch_head.png"></p>

<h2>Moloch overview</h2>

<p>To have some info indexed by moloch in a few minutes we are going to make some light random nmap scans, having in mind the interface assigned to virtual machine. If you want to use virtual interface and launch nmap scan from moloch box then you could need to change bpf filter to <em>&#8220;bpf=not port (9200 or 8005)&#8221;</em> (this isn&#8217;t, by far, the correct way, but will be enough for a quick test).</p>

<figure class='code'><figcaption><span>Quick nmap scan to index some HTTP headers</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># ./nmap -sS -Pn -n -v -p80 -iR 10000 --script=http-headers</span>
</span></code></pre></td></tr></table></div></figure>


<p>
If we take a look again to moloch web interface now we will see some pretty info:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/moloch_scan01.png"></p>

<p>We can see more info about any session clicking on &#8220;green plus&#8221; icon:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/moloch_scan02.png"></p>

<p>A new dropdown will appear and will give us some interesting options like downloading pcap (for example, to make a deeper manual analysis with wireshark), downloading data in RAW format, and showing use a set of links to make some filtering.</p>

<p>Let&#8217;s click on &#8220;User-Agent link&#8221; and then make a search to show only those indexed packets using the NSE user-agent, now you know who have scanned your network with nmap&#8217;s HTTP plugins in just a second ;).<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/moloch_scan03.png"></p>

<p>Moloch also have a useful &#8220;stats&#8221; menu to have realtime statistics about traffic being captured and indexed:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/moloch_stats.png"></p>

<h2>Indexing previously captured traffic</h2>

<p>To index traffic captured in pcap format we have to use &#8220;moloch-capture&#8221; stored in <em>&#8220;/data/moloch/bin/moloch-capture&#8221;</em>:</p>

<figure class='code'><figcaption><span>moloch-capture options</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># ./moloch-capture -h</span>
</span><span class='line'>Usage:
</span><span class='line'>  moloch-capture <span class="o">[</span>OPTION...<span class="o">]</span> - capture
</span><span class='line'>
</span><span class='line'>Help Options:
</span><span class='line'>  -h, --help         Show <span class="nb">help </span>options
</span><span class='line'>
</span><span class='line'>Application Options:
</span><span class='line'>  -c, --config       Config file name, default <span class="s1">&#39;/data/moloch/etc/config.ini&#39;</span>
</span><span class='line'>  -r, --pcapfile     Offline pcap file
</span><span class='line'>  -R, --pcapdir      Offline pcap directory, all *.pcap files will be processed
</span><span class='line'>  --recursive        When in offline pcap directory mode, recurse sub directories
</span><span class='line'>  -n, --node         Our node name, defaults to hostname.  Multiple nodes can run on same host.
</span><span class='line'>  -t, --tag          Extra tag to add to all packets, can be used multiple <span class="nb">times</span>
</span><span class='line'>  -v, --version      Show version number
</span><span class='line'>  -d, --debug        Turn on all debugging
</span><span class='line'>  --copy             When in offline mode copy the pcap files into the pcapDir from the config file
</span><span class='line'>  --dryrun           dry run, noting written to database
</span></code></pre></td></tr></table></div></figure>


<p>
I&#8217;m going to index a sample of about 7,5GB from a DNS amplification DDoS attack i had to analyze and help to mitigate some months ago, but to quickly download some pcaps to play around NetreseC have a published a good <a href="http://www.netresec.com/?page=PcapFiles">list</a>:</p>

<figure class='code'><figcaption><span>Indexing pcaps from a dir</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># ./moloch-capture -R /tmp/ddos_pcaps/ --tag ddos --copy</span>
</span></code></pre></td></tr></table></div></figure>


<p>
After some minutes i already had indexed some millions of packets and can view them just searching for tag ddos (i have stripped out map and some info to don&#8217;t disclose anything about customer / attack):<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/ddos_tags.png"></p>

<p>Let&#8217;s say we want to show every DNS datagram originating from port 53 by servers geolocated at Russia:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/ddos_filtered.png"></p>

<p>As can be seen, there were peaks of almost 60.000 packets per second (DNS answers) with an average of approximately 20.000 at regular intervals in this six minutes slot.</p>

<p>Moloch give us the chance to visualize indexed traffic from a graph&#8217;s theory point of view (&#8220;Connections&#8221; tab), using hosts as nodes and connections (with or without port) as edges:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/04/ddos_connections.png"></p>

<p>This is really useful to get an idea at a glance of what event is being analyzed, in this case we can easily spot few targets and thousands of hosts targeting them.</p>

<h2>Moloch API</h2>

<p>At the beginning of this post i said that Moloch have an API to query and get some info about indexed pcaps and so on in JSON format. At this moment probably the best way to see which calls exists is directly reading the viewer <a href="https://github.com/aol/moloch/blob/master/viewer/viewer.js">code</a>.</p>

<p>There is an example of python code to query moloch API and show some statistics:</p>

<figure class='code'><figcaption><span>Using moloch API to show some statistics</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#!/usr/bin/env python</span>
</span><span class='line'>
</span><span class='line'><span class="kn">import</span> <span class="nn">json</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">sys</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">urllib2</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="n">MOLOCH_URL</span> <span class="o">=</span> <span class="s">&#39;https://192.168.1.39:8005&#39;</span>
</span><span class='line'><span class="n">MOLOCH_USER</span> <span class="o">=</span> <span class="s">&#39;admin&#39;</span>
</span><span class='line'><span class="n">MOLOCH_PASSWORD</span> <span class="o">=</span> <span class="s">&#39;admin&#39;</span>
</span><span class='line'><span class="n">MOLOCH_REALM</span> <span class="o">=</span> <span class="s">&#39;Moloch&#39;</span>
</span><span class='line'>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="n">__name__</span><span class="o">==</span><span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class='line'>
</span><span class='line'>    <span class="c"># Set up authentication</span>
</span><span class='line'>    <span class="n">auth_handler</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">HTTPDigestAuthHandler</span><span class="p">()</span>
</span><span class='line'>    <span class="n">auth_handler</span><span class="o">.</span><span class="n">add_password</span><span class="p">(</span><span class="n">MOLOCH_REALM</span><span class="p">,</span> <span class="n">MOLOCH_URL</span><span class="p">,</span> <span class="n">MOLOCH_USER</span><span class="p">,</span> <span class="n">MOLOCH_PASSWORD</span><span class="p">)</span>
</span><span class='line'>    <span class="n">opener</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">build_opener</span><span class="p">(</span><span class="n">auth_handler</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="n">response</span> <span class="o">=</span> <span class="n">opener</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s">&#39;</span><span class="si">%s</span><span class="s">/esstats.json&#39;</span> <span class="o">%</span> <span class="n">MOLOCH_URL</span><span class="p">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
</span><span class='line'>            <span class="c"># Read html response and transform to JSON</span>
</span><span class='line'>            <span class="n">plain_answer</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span><span class='line'>            <span class="n">json_data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">plain_answer</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>            <span class="c"># Extract info</span>
</span><span class='line'>            <span class="n">node_name</span> <span class="o">=</span> <span class="n">json_data</span><span class="p">[</span><span class="s">&#39;aaData&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">&#39;name&#39;</span><span class="p">]</span>
</span><span class='line'>            <span class="n">documents_num</span> <span class="o">=</span> <span class="n">json_data</span><span class="p">[</span><span class="s">&#39;aaData&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">&#39;docs&#39;</span><span class="p">]</span>
</span><span class='line'>            <span class="n">searches_num</span> <span class="o">=</span> <span class="n">json_data</span><span class="p">[</span><span class="s">&#39;aaData&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">&#39;searches&#39;</span><span class="p">]</span>
</span><span class='line'>            <span class="n">searches_time_total</span> <span class="o">=</span> <span class="n">json_data</span><span class="p">[</span><span class="s">&#39;aaData&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">&#39;searchesTime&#39;</span><span class="p">]</span> <span class="c"># milliseconds</span>
</span><span class='line'>            <span class="n">store_size_bytes</span> <span class="o">=</span> <span class="n">json_data</span><span class="p">[</span><span class="s">&#39;aaData&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">&#39;storeSize&#39;</span><span class="p">]</span> <span class="c"># bytes</span>
</span><span class='line'>
</span><span class='line'>            <span class="c"># Show it</span>
</span><span class='line'>            <span class="n">store_size_mb</span> <span class="o">=</span> <span class="n">store_size_bytes</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">)</span>
</span><span class='line'>            <span class="n">searches_time_average_seconds</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">searches_time_total</span> <span class="o">/</span> <span class="n">searches_num</span><span class="p">)</span><span class="o">/</span><span class="mi">1000</span>
</span><span class='line'>
</span><span class='line'>            <span class="k">print</span> <span class="s">&#39;[*] Some statistics about elasticsearch at node &quot;</span><span class="si">%s</span><span class="s">&quot;&#39;</span> <span class="o">%</span> <span class="n">node_name</span>
</span><span class='line'>            <span class="k">print</span> <span class="s">&#39;   [+] There are </span><span class="si">%i</span><span class="s"> indexed documents within </span><span class="si">%i</span><span class="s"> MB of index&#39;</span>\
</span><span class='line'>                  <span class="o">%</span> <span class="p">(</span><span class="n">documents_num</span><span class="p">,</span> <span class="n">store_size_mb</span><span class="p">)</span>
</span><span class='line'>            <span class="k">print</span> <span class="s">&#39;   [+] This elasticsearch node has served up </span><span class="si">%i</span><span class="s"> queries with an average</span><span class="se">\</span>
</span><span class='line'><span class="s">            of </span><span class="si">%f</span><span class="s"> seconds per query&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">searches_num</span><span class="p">,</span> <span class="n">searches_time_average_seconds</span><span class="p">)</span>
</span><span class='line'>            <span class="k">print</span> <span class="s">&#39;[-]&#39;</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">except</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span>
</span><span class='line'>        <span class="k">raise</span> <span class="n">e</span>
</span></code></pre></td></tr></table></div></figure>


<p>
This simple code will show something similar to this:</p>

<figure class='code'><figcaption><span>Output for moloch_api_example.py</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>python moloch_api_example.py
</span><span class='line'><span class="o">[</span>*<span class="o">]</span> Some statistics about elasticsearch at node <span class="s2">&quot;molocha&quot;</span>
</span><span class='line'>   <span class="o">[</span>+<span class="o">]</span> There are 1624416 indexed documents within 963 MB of index
</span><span class='line'>   <span class="o">[</span>+<span class="o">]</span> This elasticsearch node has served up 1042 queries with an average of 0.012000 seconds per query
</span><span class='line'><span class="o">[</span>-<span class="o">]</span>
</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>That is all for now, hope you liked this and find it useful, i think moloch is a really powerful tool and will turn to a must-have in network forensics as well as saving us countless hours when dealing with big amounts of network traffic.</p>

<p>See you soon!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Indexing PDF for OSINT and pentesting]]></title>
    <link href="http://blog.alejandronolla.com/2013/03/23/indexing-pdf-for-osint-and-pentesting/"/>
    <updated>2013-03-23T10:26:00+01:00</updated>
    <id>http://blog.alejandronolla.com/2013/03/23/indexing-pdf-for-osint-and-pentesting</id>
    <content type="html"><![CDATA[<p>Most of us, when conducting OSINT tasks or gathering information for preparing a pentest, draw on Google hacking techniques like <strong>site:company.acme filetype:pdf &#8220;for internal use only&#8221;</strong> or something similar to search for potential sensitive information uploaded by mistake. Other times, a customer ask us to know if they have leaked in a negligence this kind of sensitive information and we proceed to make some google hacking fu. <br/>
But, what happens if we don&#8217;t want to make this queries against Google and, furthermore, follow links from search that could potentially leak referers? Sure we could download documents and review them manually in local but it&#8217;s boring and time consuming. Here is where <a href="http://lucene.apache.org/solr/">Apache Solr</a> comes into play for processing documents and create index of them to give us almost real time searching capabilities.<!-- more --></p>

<h2>What is Solr?</h2>

<p>Solr is a schema based (also with dynamics field support) search solution built upon Apache Lucene providing full-text searching capabilities, document processing, REST API to fetch results in various formats like XML or JSON, etc.  Solr allows us to process document indexing with multiple options regarding of how to treat text, how to tokenize it, convert (or not) to lowercase automatically, build distributed cluster, automatic duplicates document detection and so.</p>

<h2>Setting up Solr</h2>

<p>There are a lot of stuff about how to install Solr so i&#8217;m not going to cover it, just specific core options for this quick&#8217;n dirty solution. First thing to do is creating core config and data dir, in this case i created <em>/opt/solr/pdfosint/</em> and <em>/opt/solr/pdfosintdata/</em> to store config and document data respectively.</p>

<p>To set schema up just create <em>/opt/solr/pdfosint/conf/schema.xml</em> file with following content:</p>

<figure class='code'><figcaption><span>schema.xml content for pdfosint core</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</span>
</span><span class='line'><span class="nt">&lt;schema</span> <span class="na">name=</span><span class="s">&quot;pastebincom&quot;</span> <span class="na">version=</span><span class="s">&quot;1.5&quot;</span><span class="nt">&gt;</span>
</span><span class='line'> <span class="nt">&lt;fields&gt;</span>
</span><span class='line'>   <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;id&quot;</span> <span class="na">type=</span><span class="s">&quot;uuid&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">default=</span><span class="s">&quot;NEW&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;text&quot;</span> <span class="na">type=</span><span class="s">&quot;text_general&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;timestamp&quot;</span> <span class="na">type=</span><span class="s">&quot;date&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">default=</span><span class="s">&quot;NOW&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;false&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;field</span> <span class="na">name=</span><span class="s">&quot;_version_&quot;</span> <span class="na">type=</span><span class="s">&quot;long&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;dynamicField</span> <span class="na">name=</span><span class="s">&quot;attr_*&quot;</span> <span class="na">type=</span><span class="s">&quot;text_general&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="na">stored=</span><span class="s">&quot;true&quot;</span> <span class="na">multiValued=</span><span class="s">&quot;true&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'> <span class="nt">&lt;/fields&gt;</span>
</span><span class='line'>
</span><span class='line'> <span class="nt">&lt;types&gt;</span>
</span><span class='line'>   <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;string&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.StrField&quot;</span> <span class="na">sortMissingLast=</span><span class="s">&quot;true&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;long&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TrieLongField&quot;</span> <span class="na">precisionStep=</span><span class="s">&quot;0&quot;</span> <span class="na">positionIncrementGap=</span><span class="s">&quot;0&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;date&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TrieDateField&quot;</span> <span class="na">precisionStep=</span><span class="s">&quot;0&quot;</span> <span class="na">positionIncrementGap=</span><span class="s">&quot;0&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;uuid&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.UUIDField&quot;</span> <span class="na">indexed=</span><span class="s">&quot;true&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>   <span class="nt">&lt;fieldType</span> <span class="na">name=</span><span class="s">&quot;text_general&quot;</span> <span class="na">class=</span><span class="s">&quot;solr.TextField&quot;</span> <span class="na">positionIncrementGap=</span><span class="s">&quot;100&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;index&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.WhitespaceTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>      <span class="nt">&lt;analyzer</span> <span class="na">type=</span><span class="s">&quot;query&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;tokenizer</span> <span class="na">class=</span><span class="s">&quot;solr.WhitespaceTokenizerFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>        <span class="nt">&lt;filter</span> <span class="na">class=</span><span class="s">&quot;solr.LowerCaseFilterFactory&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'>      <span class="nt">&lt;/analyzer&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/fieldType&gt;</span>
</span><span class='line'> <span class="nt">&lt;/types&gt;</span>
</span><span class='line'><span class="nt">&lt;/schema&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Just a quick review of config for schema.xml, i specified an id field to be unique (UUID), a text field to store text itself, timestamp to be setted to date when document is pushed into Solr, <em>version</em> to track index version (internal Solr use to replicate, and so) and a dynamic field named attr_* to store any no specified value in schema and provided by parser. At last, i specified how to treat indexing and querying, for tokenize i use whitespice (splice words based just on whitespace without caring about special punctuaction) and convert it to lowercase. If you want to know more about text processing i would recommend <a href="http://www.packtpub.com/python-text-processing-nltk-20-cookbook/book">Python Text Processing with NLTK 2.0 Cookbok</a> as an introduction, <a href="http://shop.oreilly.com/product/9780596516499.do">Natural Language Processing with Python</a> for a more in-depth usage (both Python based) and <a href="https://www.coursera.org/course/nlangp">Natural Language Processing</a> online course available in Coursera.</p>

<p>Next step is notyfing Solr about new core, just adding to <em>/opt/solr/solr.xml/</em></p>

<figure class='code'><figcaption><span>new core for PDF indexing</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;cores&gt;</span>
</span><span class='line'>  ...
</span><span class='line'>  <span class="nt">&lt;core</span> <span class="na">name=</span><span class="s">&quot;pdfosint&quot;</span> <span class="na">instanceDir=</span><span class="s">&quot;pdfosint&quot;</span><span class="nt">/&gt;</span>
</span><span class='line'><span class="nt">&lt;/cores&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now only left to provide Solr with binary document processing capabilities through a <a href="http://wiki.apache.org/solr/SolrRequestHandler">request handler</a>, in that case, only for <em>pdfosint</em> core. For this create <em>/opt/solr/pdfosint/solrconfig.xml</em> (we can always copy provided example with Solr and modify when needed) and specify request handler:</p>

<figure class='code'><figcaption><span>setting up solr request handler for binary documents</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>  <span class="nt">&lt;requestHandler</span> <span class="na">name=</span><span class="s">&quot;/update/extract&quot;</span> <span class="na">class=</span><span class="s">&quot;org.apache.solr.handler.extraction.ExtractingRequestHandler&quot;</span> <span class="nt">&gt;</span>
</span><span class='line'>    <span class="nt">&lt;lst</span> <span class="na">name=</span><span class="s">&quot;defaults&quot;</span><span class="nt">&gt;</span>
</span><span class='line'>        <span class="nt">&lt;str</span> <span class="na">name=</span><span class="s">&quot;fmap.content&quot;</span><span class="nt">&gt;</span>text<span class="nt">&lt;/str&gt;</span>
</span><span class='line'>        <span class="nt">&lt;str</span> <span class="na">name=</span><span class="s">&quot;lowernames&quot;</span><span class="nt">&gt;</span>true<span class="nt">&lt;/str&gt;</span>
</span><span class='line'>        <span class="nt">&lt;str</span> <span class="na">name=</span><span class="s">&quot;uprefix&quot;</span><span class="nt">&gt;</span>attr_<span class="nt">&lt;/str&gt;</span>
</span><span class='line'>        <span class="nt">&lt;str</span> <span class="na">name=</span><span class="s">&quot;captureAttr&quot;</span><span class="nt">&gt;</span>true<span class="nt">&lt;/str&gt;</span>
</span><span class='line'>    <span class="nt">&lt;/lst&gt;</span>
</span><span class='line'>  <span class="nt">&lt;/requestHandler&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>A quick review of this, class could changed depending on version and classes names, fmap.content specify to index extracted text to a field called <em>text</em>, lowernames specify converting to lowercase all processed documents, uprefix specify how to handled field parsed and not provided in schema.xml (in that case use dynamic attribute with a suffix of <em>attr_</em>) and captureAttr to specify indexing parsed attributes into separate fields. To know more about ExtractingRequestHandler <a href="http://wiki.apache.org/solr/ExtractingRequestHandler">here</a>.<br/>
Now we have to install required libraries to do binary parsing and indexing, for this, i have created <em>/opt/solr/extract/</em> and copied <em>solr-cell-4.2.0.jar</em> from <em>dist</em> directory inside of Solr distribution archive and also copied to the same folder everything from <em>contrib/extraction/lib/</em> again from distribution archive.</p>

<p>At last, adding this line to <em>/opt/solr/pdfosint/solrconfix.xml</em> to specify from where load libraries:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'>...
</span><span class='line'><span class="nt">&lt;lib</span> <span class="na">dir=</span><span class="s">&quot;/opt/solr/extract&quot;</span> <span class="na">regex=</span><span class="s">&quot;.*\.jar&quot;</span> <span class="nt">/&gt;</span>
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<p>To know more about this process and more recipes, i strongly recommend [Apache Solr 4 Cookbook] (http://www.packtpub.com/apache-solr-4-cookbook/book).</p>

<h2>Indexing and digging data</h2>

<p>Now we have a extracting and indexing handler at <em>http://localhost:8080/solr/pdfosint/update/extract/</em> so only rest to send PDF to Solr and analyze them. The easyiest way once downloaded (or maybe  fetched from a meterpreter session? }:) ) is sending them with curl to Solr:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span><span class="k">for </span>i in <span class="sb">`</span>ls /tmp/pdf/*.pdf<span class="sb">`</span>; <span class="k">do </span>curl <span class="s2">&quot;http://localhost:8080/solr/pdfosint/update/extract/?commit=true&quot;</span> -F <span class="s2">&quot;myfile=@$i&quot;</span>; <span class="k">done</span>;
</span></code></pre></td></tr></table></div></figure>


<p>After a while, depending on several factors like machine specs and documents size, we should have an index like this:
<img src="http://blog.alejandronolla.com/images/upload/2013/03/solr_index.png"></p>

<p>So now we try a query to find documents with phrase <em>&#8220;internal use only&#8221;</em> and bingo!:
<img src="http://blog.alejandronolla.com/images/upload/2013/03/solr_query.png"></p>

<p>It&#8217;s important to have in mind the fact that Solr split words and treat them before indexing when doing queries, to see how a phrase should be treated and indexed by Solr when submitted we can do an analysis with builtin interface:<br/>
<img src="http://blog.alejandronolla.com/images/upload/2013/03/solr_analysis.png"></p>

<p>I hope you find it useful and give it a try, see you soon!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Embrace yourselves, blog is coming...]]></title>
    <link href="http://blog.alejandronolla.com/2013/03/18/embrace-yourselves/"/>
    <updated>2013-03-18T23:45:00+01:00</updated>
    <id>http://blog.alejandronolla.com/2013/03/18/embrace-yourselves</id>
    <content type="html"><![CDATA[<p>I have decided to give a try to octopress for setting up a basic blog to publish some stuff hopefully useful to someone.</p>
]]></content>
  </entry>
  
</feed>
